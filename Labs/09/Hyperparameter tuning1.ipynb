{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3af3f3-5fcc-4118-95bc-181e8c36c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create a folder for the script files\n",
    "script_folder = 'src'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec17580-15b6-4f65-b4ca-ce25412bda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "    mlflow.log_metric(\"training_accuracy_score\", acc)\n",
    "\n",
    "    # calculate AUC\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(\"ROC-Curve.png\")\n",
    "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e2905-7bb9-4eab-8393-6776634abd5d",
   "metadata": {},
   "source": [
    "Configure and run a command job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e7e82-92ea-4815-86d5-4a2dd1c430f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py --training_data ${{inputs.diabetes_data}} --reg_rate ${{inputs.reg_rate}}\",\n",
    "    inputs={\n",
    "        \"diabetes_data\": Input(\n",
    "            type=AssetTypes.URI_FILE, \n",
    "            path=\"azureml:diabetes-data:1\"\n",
    "            ),\n",
    "        \"reg_rate\": 0.01,\n",
    "    },\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-mlflow\",\n",
    "    experiment_name=\"diabetes-training\", \n",
    "    tags={\"model_type\": \"LogisticRegression\"}\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a031d73-f051-4865-beca-6ea46c05200f",
   "metadata": {},
   "source": [
    "## Define the search space\n",
    "\n",
    "When your command job has completed successfully, you can configure and run a sweep job. \n",
    "\n",
    "First, you'll need to specify the search space for your hyperparameter. To train three models, each with a different regularization rate (`0.01`, `0.1`, or `1`), you can define the search space with a `Choice` hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27440b-ec52-4780-838a-d19d8dea3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "command_job_for_sweep = job(\n",
    "    reg_rate=Choice(values=[0.01, 0.1, 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bc9c2-217e-43e0-b5fd-247ab4803422",
   "metadata": {},
   "source": [
    "## Configure and submit the sweep job\n",
    "\n",
    "You'll use the sweep function to do hyperparameter tuning on your training script. To configure a sweep job, you'll need to configure the following:\n",
    "\n",
    "- `compute`: Name of the compute target to execute the job on.\n",
    "- `sampling_algorithm`: The hyperparameter sampling algorithm to use over the search space. Allowed values are `random`, `grid` and `bayesian`.\n",
    "- `primary_metric`: The name of the primary metric reported by each trial job. The metric must be logged in the user's training script using `mlflow.log_metric()` with the same corresponding metric name.\n",
    "- `goal`: The optimization goal of the `primary_metric`. The allowed values are `maximize` and `minimize`.\n",
    "- `limits`: Limits for the sweep job. For example, the maximum amount of trials or models you want to train.\n",
    "\n",
    "Note that the command job is used as the base for the sweep job. The configuration for the command job will be reused by the sweep job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d01f6a-cd54-4d58-9aa8-6184f7e80f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"aml-cluster\",\n",
    "    sampling_algorithm=\"grid\",\n",
    "    primary_metric=\"training_accuracy_score\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "# set the name of the sweep job experiment\n",
    "sweep_job.experiment_name=\"sweep-diabetes\"\n",
    "\n",
    "# define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269579a-2697-4b65-94f5-ca867b9dc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_sweep_job = ml_client.create_or_update(sweep_job)\n",
    "aml_url = returned_sweep_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c4e15-f07d-46fe-a9ae-625ddfcca546",
   "metadata": {},
   "source": [
    "When the job is completed, navigate to the job overview. The **Trials** tab will show all models that have been trained and how the `Accuracy` score differs for each regularization rate value you tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21dc2ae-b012-4660-bddd-4f6205cab64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
